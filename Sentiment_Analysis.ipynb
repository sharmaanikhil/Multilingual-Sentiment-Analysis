{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-02-16T17:24:26.004170Z",
          "iopub.status.busy": "2025-02-16T17:24:26.003834Z",
          "iopub.status.idle": "2025-02-16T17:24:26.912722Z",
          "shell.execute_reply": "2025-02-16T17:24:26.911982Z",
          "shell.execute_reply.started": "2025-02-16T17:24:26.004141Z"
        },
        "id": "foY_53I5IJA-",
        "outputId": "64335b8b-5629-434e-84a6-babf4167d27f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/kaggle/input/llama-3.1/transformers/8b-instruct/2/model.safetensors.index.json\n",
            "/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00003-of-00004.safetensors\n",
            "/kaggle/input/llama-3.1/transformers/8b-instruct/2/config.json\n",
            "/kaggle/input/llama-3.1/transformers/8b-instruct/2/LICENSE\n",
            "/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00001-of-00004.safetensors\n",
            "/kaggle/input/llama-3.1/transformers/8b-instruct/2/README.md\n",
            "/kaggle/input/llama-3.1/transformers/8b-instruct/2/USE_POLICY.md\n",
            "/kaggle/input/llama-3.1/transformers/8b-instruct/2/tokenizer.json\n",
            "/kaggle/input/llama-3.1/transformers/8b-instruct/2/tokenizer_config.json\n",
            "/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00004-of-00004.safetensors\n",
            "/kaggle/input/llama-3.1/transformers/8b-instruct/2/special_tokens_map.json\n",
            "/kaggle/input/llama-3.1/transformers/8b-instruct/2/.gitattributes\n",
            "/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00002-of-00004.safetensors\n",
            "/kaggle/input/llama-3.1/transformers/8b-instruct/2/generation_config.json\n",
            "/kaggle/input/llama-3.1/transformers/8b-instruct/2/original/consolidated.00.pth\n",
            "/kaggle/input/llama-3.1/transformers/8b-instruct/2/original/params.json\n",
            "/kaggle/input/llama-3.1/transformers/8b-instruct/2/original/tokenizer.model\n",
            "/kaggle/input/multi-lingual-sentiment-analysis/sample_submission.csv\n",
            "/kaggle/input/multi-lingual-sentiment-analysis/train.csv\n",
            "/kaggle/input/multi-lingual-sentiment-analysis/test.csv\n"
          ]
        }
      ],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy9nqIigIJBF"
      },
      "source": [
        "# Basic Downloads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T17:24:26.914068Z",
          "iopub.status.busy": "2025-02-16T17:24:26.913669Z",
          "iopub.status.idle": "2025-02-16T17:24:54.582179Z",
          "shell.execute_reply": "2025-02-16T17:24:54.581026Z",
          "shell.execute_reply.started": "2025-02-16T17:24:26.914042Z"
        },
        "id": "YEqT34A7IJBH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install bitsandbytes\n",
        "!pip install accelerate\n",
        "!pip install peft\n",
        "!pip install evaluate\n",
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T17:24:54.584543Z",
          "iopub.status.busy": "2025-02-16T17:24:54.584184Z",
          "iopub.status.idle": "2025-02-16T17:25:16.599600Z",
          "shell.execute_reply": "2025-02-16T17:25:16.598934Z",
          "shell.execute_reply.started": "2025-02-16T17:24:54.584496Z"
        },
        "id": "29jUUFY6IJBI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from datasets import load_from_disk, load_dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from peft import prepare_model_for_kbit_training, LoraConfig, PeftModel, get_peft_model\n",
        "import torch\n",
        "from rich import print as rprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "47df278d2d124b8082f08132921cdaa9"
          ]
        },
        "execution": {
          "iopub.execute_input": "2025-02-16T17:25:16.601581Z",
          "iopub.status.busy": "2025-02-16T17:25:16.600897Z",
          "iopub.status.idle": "2025-02-16T17:25:16.940212Z",
          "shell.execute_reply": "2025-02-16T17:25:16.939497Z",
          "shell.execute_reply.started": "2025-02-16T17:25:16.601546Z"
        },
        "id": "RsZsuO7UIJBJ",
        "outputId": "6b3109c2-919d-4cef-935b-23c4a614f1b8",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47df278d2d124b8082f08132921cdaa9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['ID', 'sentence', 'label', 'language'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = load_dataset(\"csv\", data_files=\"/kaggle/input/multi-lingual-sentiment-analysis/train.csv\")\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T17:25:16.941583Z",
          "iopub.status.busy": "2025-02-16T17:25:16.941245Z",
          "iopub.status.idle": "2025-02-16T17:25:16.960429Z",
          "shell.execute_reply": "2025-02-16T17:25:16.959654Z",
          "shell.execute_reply.started": "2025-02-16T17:25:16.941552Z"
        },
        "id": "seiv0xqeIJBK",
        "outputId": "030db9d2-7f71-4c04-88e6-f60a8c093641",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">=== Unique value counts for train set ===\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "=== Unique value counts for train set ===\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Column: label, Unique values: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Column: label, Unique values: \u001b[1;36m2\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sample values: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Positive'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">507</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Negative'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">493</span><span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Sample values: \u001b[1m{\u001b[0m\u001b[32m'Positive'\u001b[0m: \u001b[1;36m507\u001b[0m, \u001b[32m'Negative'\u001b[0m: \u001b[1;36m493\u001b[0m\u001b[1m}\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Column: language, Unique values: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Column: language, Unique values: \u001b[1;36m13\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sample values: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'bn'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gu'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'ta'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pa'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'bd'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'as'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'te'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'or'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'ml'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">76</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'hi'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77</span>,\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">'mr'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'ur'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'kn'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77</span><span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Sample values: \u001b[1m{\u001b[0m\u001b[32m'bn'\u001b[0m: \u001b[1;36m77\u001b[0m, \u001b[32m'gu'\u001b[0m: \u001b[1;36m77\u001b[0m, \u001b[32m'ta'\u001b[0m: \u001b[1;36m77\u001b[0m, \u001b[32m'pa'\u001b[0m: \u001b[1;36m77\u001b[0m, \u001b[32m'bd'\u001b[0m: \u001b[1;36m77\u001b[0m, \u001b[32m'as'\u001b[0m: \u001b[1;36m77\u001b[0m, \u001b[32m'te'\u001b[0m: \u001b[1;36m77\u001b[0m, \u001b[32m'or'\u001b[0m: \u001b[1;36m77\u001b[0m, \u001b[32m'ml'\u001b[0m: \u001b[1;36m76\u001b[0m, \u001b[32m'hi'\u001b[0m: \u001b[1;36m77\u001b[0m,\n",
              "\u001b[32m'mr'\u001b[0m: \u001b[1;36m77\u001b[0m, \u001b[32m'ur'\u001b[0m: \u001b[1;36m77\u001b[0m, \u001b[32m'kn'\u001b[0m: \u001b[1;36m77\u001b[0m\u001b[1m}\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Iterate over each dataset split (train, test, validation, etc.)\n",
        "for split, ds in dataset.items():\n",
        "    rprint(f\"=== Unique value counts for {split} set ===\\n\")\n",
        "    columns = ['label', 'language']\n",
        "    for column in columns:\n",
        "        unique_counts = Counter(ds[column])  # Count occurrences of each unique value\n",
        "        rprint(f\"Column: {column}, Unique values: {len(unique_counts)}\")\n",
        "        rprint(f\"Sample values: {dict(list(unique_counts.items()))}\")  # Print first 5 unique values\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T17:25:16.961385Z",
          "iopub.status.busy": "2025-02-16T17:25:16.961109Z",
          "iopub.status.idle": "2025-02-16T17:25:16.967215Z",
          "shell.execute_reply": "2025-02-16T17:25:16.966398Z",
          "shell.execute_reply.started": "2025-02-16T17:25:16.961358Z"
        },
        "id": "HP-tZ2YDIJBK",
        "outputId": "f34e4c9f-bb44-42ef-ba54-78844ce865f1",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['ID', 'sentence', 'label', 'language'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "9469c4c859da44859da2b069faf34dcb"
          ]
        },
        "execution": {
          "iopub.execute_input": "2025-02-16T17:25:16.968445Z",
          "iopub.status.busy": "2025-02-16T17:25:16.968147Z",
          "iopub.status.idle": "2025-02-16T17:25:17.053649Z",
          "shell.execute_reply": "2025-02-16T17:25:17.052735Z",
          "shell.execute_reply.started": "2025-02-16T17:25:16.968416Z"
        },
        "id": "_VZfCVoWIJBM",
        "outputId": "a973aeba-d990-447e-d6b5-d05d18752df3",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9469c4c859da44859da2b069faf34dcb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def fix_labels(example):\n",
        "    label_map = {\"Positive\": 1, \"Negative\": 0}  # Map labels to integers\n",
        "    example[\"label\"] = label_map.get(example[\"label\"], -1)  # Assign -1 for unknown labels\n",
        "    return example\n",
        "\n",
        "dataset = dataset.map(fix_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RCqlUjYIJBN"
      },
      "source": [
        "## Loading the model and configuring it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T17:25:17.055822Z",
          "iopub.status.busy": "2025-02-16T17:25:17.055632Z",
          "iopub.status.idle": "2025-02-16T17:25:18.092989Z",
          "shell.execute_reply": "2025-02-16T17:25:18.092384Z",
          "shell.execute_reply.started": "2025-02-16T17:25:17.055805Z"
        },
        "id": "G59WM-jqIJBO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM\n",
        "from transformers import DataCollatorWithPadding\n",
        "from transformers import LlamaConfig, LlamaForCausalLM,LlamaForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T17:25:18.094342Z",
          "iopub.status.busy": "2025-02-16T17:25:18.094132Z",
          "iopub.status.idle": "2025-02-16T17:25:18.097606Z",
          "shell.execute_reply": "2025-02-16T17:25:18.096871Z",
          "shell.execute_reply.started": "2025-02-16T17:25:18.094324Z"
        },
        "id": "EPveLb2gIJBO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# # Quantization configuration\n",
        "# model_path = \"/kaggle/input/llama-3.1/transformers/8b-instruct/2\"\n",
        "\n",
        "# bnb_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True,\n",
        "#     bnb_4bit_use_double_quant=False,\n",
        "#     bnb_4bit_quant_type=\"nf4\",\n",
        "#     bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "# )\n",
        "\n",
        "# # Loading the model and tokenizer\n",
        "\n",
        "# model = AutoModelForCausalLM.from_pretrained(model_path,quantization_config=bnb_config,\n",
        "#                                              device_map=\"auto\")\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\n",
        "#     model_path,\n",
        "#     model_max_length=1024,\n",
        "#     padding_side=\"left\",\n",
        "#     add_eos_token=True)\n",
        "# tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T17:25:18.098586Z",
          "iopub.status.busy": "2025-02-16T17:25:18.098345Z",
          "iopub.status.idle": "2025-02-16T17:25:18.714406Z",
          "shell.execute_reply": "2025-02-16T17:25:18.713731Z",
          "shell.execute_reply.started": "2025-02-16T17:25:18.098567Z"
        },
        "id": "7NfXw8tcIJBO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model_id = \"/kaggle/input/llama-3.1/transformers/8b-instruct/2\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, model_max_length=1024)\n",
        "# set pad token id\n",
        "tokenizer.pad_token=tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T17:25:18.715498Z",
          "iopub.status.busy": "2025-02-16T17:25:18.715205Z",
          "iopub.status.idle": "2025-02-16T17:25:18.719494Z",
          "shell.execute_reply": "2025-02-16T17:25:18.718827Z",
          "shell.execute_reply.started": "2025-02-16T17:25:18.715469Z"
        },
        "id": "mSTbbL0TIJBP",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def tokenize(example):\n",
        "    return tokenizer(example[\"sentence\"], padding=True, truncation=True, max_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "a6a1d05a533841fba46662897f2b40d7"
          ]
        },
        "execution": {
          "iopub.execute_input": "2025-02-16T17:25:18.720577Z",
          "iopub.status.busy": "2025-02-16T17:25:18.720277Z",
          "iopub.status.idle": "2025-02-16T17:25:19.482581Z",
          "shell.execute_reply": "2025-02-16T17:25:19.481758Z",
          "shell.execute_reply.started": "2025-02-16T17:25:18.720539Z"
        },
        "id": "yjtgcGE_IJBP",
        "outputId": "70152add-66db-4036-d8f6-08047ce07a66",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6a1d05a533841fba46662897f2b40d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['ID', 'label', 'language', 'input_ids', 'attention_mask'],\n",
            "        num_rows: 1000\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "tokenized_ds = dataset.map(tokenize, batched=True, num_proc=4, remove_columns=['sentence'])\n",
        "print(tokenized_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T17:25:19.483706Z",
          "iopub.status.busy": "2025-02-16T17:25:19.483468Z",
          "iopub.status.idle": "2025-02-16T17:25:19.496399Z",
          "shell.execute_reply": "2025-02-16T17:25:19.495709Z",
          "shell.execute_reply.started": "2025-02-16T17:25:19.483683Z"
        },
        "id": "hs5VuukcIJBQ",
        "outputId": "2bf84a6d-03be-4caa-8ee4-22687adeecd9",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['ID', 'label', 'language', 'input_ids', 'attention_mask'],\n",
            "        num_rows: 930\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['ID', 'label', 'language', 'input_ids', 'attention_mask'],\n",
            "        num_rows: 70\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "ds_split = tokenized_ds['train'].train_test_split(test_size=0.07,seed=50)\n",
        "print(ds_split)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlffwPD0IJBQ"
      },
      "source": [
        "# Data Collator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T17:25:19.497453Z",
          "iopub.status.busy": "2025-02-16T17:25:19.497172Z",
          "iopub.status.idle": "2025-02-16T17:25:19.511216Z",
          "shell.execute_reply": "2025-02-16T17:25:19.510335Z",
          "shell.execute_reply.started": "2025-02-16T17:25:19.497421Z"
        },
        "id": "X7lGjRv5IJBQ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer,padding='max_length', max_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T17:25:19.512298Z",
          "iopub.status.busy": "2025-02-16T17:25:19.512047Z",
          "iopub.status.idle": "2025-02-16T17:25:19.525533Z",
          "shell.execute_reply": "2025-02-16T17:25:19.524747Z",
          "shell.execute_reply.started": "2025-02-16T17:25:19.512272Z"
        },
        "id": "m7Vluyc5IJBR",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch, gc\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "1636cda632de463e95365e89519cf4e2"
          ]
        },
        "execution": {
          "iopub.execute_input": "2025-02-16T17:25:19.526692Z",
          "iopub.status.busy": "2025-02-16T17:25:19.526457Z",
          "iopub.status.idle": "2025-02-16T17:26:22.579412Z",
          "shell.execute_reply": "2025-02-16T17:26:22.578695Z",
          "shell.execute_reply.started": "2025-02-16T17:25:19.526674Z"
        },
        "id": "3H7MmpWFIJBR",
        "outputId": "bd063284-e373-468c-e892-2ca7c7004829",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1636cda632de463e95365e89519cf4e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/llama-3.1/transformers/8b-instruct/2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    llm_int8_enable_fp32_cpu_offload=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_id,\n",
        "                                                           num_labels=2,\n",
        "                                                           pad_token_id=tokenizer.eos_token_id,\n",
        "                                                           quantization_config=bnb_config,\n",
        "                                                           device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "ac48d2c3f2f543c5af5ebd1ebed37e3f"
          ]
        },
        "execution": {
          "iopub.execute_input": "2025-02-16T17:26:22.580373Z",
          "iopub.status.busy": "2025-02-16T17:26:22.580150Z",
          "iopub.status.idle": "2025-02-16T17:26:23.216759Z",
          "shell.execute_reply": "2025-02-16T17:26:23.216141Z",
          "shell.execute_reply.started": "2025-02-16T17:26:22.580353Z"
        },
        "id": "z-EpmyISIJBR",
        "outputId": "31208a9d-9fa5-47ff-db58-c0eb3947b4c5",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac48d2c3f2f543c5af5ebd1ebed37e3f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.79k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import evaluate\n",
        "metric = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels, average=\"macro\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPOQFF9WIJBS"
      },
      "source": [
        "# Checking Models and Tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T17:26:23.217837Z",
          "iopub.status.busy": "2025-02-16T17:26:23.217596Z",
          "iopub.status.idle": "2025-02-16T17:26:23.223909Z",
          "shell.execute_reply": "2025-02-16T17:26:23.223067Z",
          "shell.execute_reply.started": "2025-02-16T17:26:23.217817Z"
        },
        "id": "e5s4xEOUIJBS",
        "outputId": "41361a79-e3d3-4028-b354-5fe073fd6ad9",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LlamaForSequenceClassification(\n",
            "  (model): LlamaModel(\n",
            "    (embed_tokens): Embedding(128256, 4096, padding_idx=128009)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x LlamaDecoderLayer(\n",
            "        (self_attn): LlamaAttention(\n",
            "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "        )\n",
            "        (mlp): LlamaMLP(\n",
            "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
            "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
            "      )\n",
            "    )\n",
            "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
            "    (rotary_emb): LlamaRotaryEmbedding()\n",
            "  )\n",
            "  (score): Linear(in_features=4096, out_features=2, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JOueSnOIJBS"
      },
      "source": [
        "# Fine Tune with LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T17:26:23.225123Z",
          "iopub.status.busy": "2025-02-16T17:26:23.224824Z",
          "iopub.status.idle": "2025-02-16T17:26:23.241631Z",
          "shell.execute_reply": "2025-02-16T17:26:23.240945Z",
          "shell.execute_reply.started": "2025-02-16T17:26:23.225102Z"
        },
        "id": "b1D0yJj4IJBS",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#lora\n",
        "from peft import LoraConfig, TaskType, LoraModel\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    inference_mode=False,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T17:26:23.242597Z",
          "iopub.status.busy": "2025-02-16T17:26:23.242329Z",
          "iopub.status.idle": "2025-02-16T17:26:23.448684Z",
          "shell.execute_reply": "2025-02-16T17:26:23.447964Z",
          "shell.execute_reply.started": "2025-02-16T17:26:23.242564Z"
        },
        "id": "7wQ4aQa4IJBx",
        "outputId": "9b783b22-44f3-48de-8d9f-a82538d03b61",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 6,823,936 || all params: 7,511,756,800 || trainable%: 0.0908\n",
            "PeftModelForSequenceClassification(\n",
            "  (base_model): LoraModel(\n",
            "    (model): LlamaForSequenceClassification(\n",
            "      (model): LlamaModel(\n",
            "        (embed_tokens): Embedding(128256, 4096, padding_idx=128009)\n",
            "        (layers): ModuleList(\n",
            "          (0-31): 32 x LlamaDecoderLayer(\n",
            "            (self_attn): LlamaAttention(\n",
            "              (q_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "                (lora_magnitude_vector): ModuleDict()\n",
            "              )\n",
            "              (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "              (v_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "                (lora_magnitude_vector): ModuleDict()\n",
            "              )\n",
            "              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "            )\n",
            "            (mlp): LlamaMLP(\n",
            "              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "              (act_fn): SiLU()\n",
            "            )\n",
            "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
            "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
            "        (rotary_emb): LlamaRotaryEmbedding()\n",
            "      )\n",
            "      (score): ModulesToSaveWrapper(\n",
            "        (original_module): Linear(in_features=4096, out_features=2, bias=False)\n",
            "        (modules_to_save): ModuleDict(\n",
            "          (default): Linear(in_features=4096, out_features=2, bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from peft import get_peft_model\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "lora_model = get_peft_model(model, lora_config)\n",
        "lora_model.print_trainable_parameters()\n",
        "print(lora_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T17:26:23.449767Z",
          "iopub.status.busy": "2025-02-16T17:26:23.449461Z",
          "iopub.status.idle": "2025-02-16T17:26:23.454803Z",
          "shell.execute_reply": "2025-02-16T17:26:23.454101Z",
          "shell.execute_reply.started": "2025-02-16T17:26:23.449738Z"
        },
        "id": "A1qMwIpPIJBx",
        "outputId": "ee228891-0895-4f80-a38e-38a14e0a9762",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'default': LoraConfig(task_type=<TaskType.SEQ_CLS: 'SEQ_CLS'>, peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='/kaggle/input/llama-3.1/transformers/8b-instruct/2', revision=None, inference_mode=False, r=16, target_modules={'v_proj', 'q_proj'}, exclude_modules=None, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=['classifier', 'score'], init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, eva_config=None, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False)}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lora_model.peft_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T17:26:23.455805Z",
          "iopub.status.busy": "2025-02-16T17:26:23.455604Z",
          "iopub.status.idle": "2025-02-16T17:26:23.497811Z",
          "shell.execute_reply": "2025-02-16T17:26:23.497202Z",
          "shell.execute_reply.started": "2025-02-16T17:26:23.455787Z"
        },
        "id": "fEiGMxVSIJBy",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments( output_dir='lora_llama_8b_ct',\n",
        "                                  eval_strategy=\"steps\",\n",
        "                                  eval_steps=50,\n",
        "                                  num_train_epochs=2,\n",
        "                                  per_device_train_batch_size=4,\n",
        "                                  per_device_eval_batch_size=4,\n",
        "                                  bf16=False,\n",
        "                                  fp16=True,\n",
        "                                  tf32=False,\n",
        "                                  gradient_accumulation_steps=2,\n",
        "                                  adam_beta1=0.05,\n",
        "                                  adam_beta2=0.995,\n",
        "                                  learning_rate=1e-4,\n",
        "                                  weight_decay=0.02,\n",
        "                                  logging_dir='logs',\n",
        "                                  logging_strategy=\"steps\",\n",
        "                                  logging_steps = 50,\n",
        "                                  save_steps=50,\n",
        "                                  save_total_limit=20,\n",
        "                                  report_to='none',\n",
        "                                  half_precision_backend = 'amp',\n",
        "                                  load_best_model_at_end = True,\n",
        "                                  #use_reentrant=True\n",
        "                                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T17:26:23.500797Z",
          "iopub.status.busy": "2025-02-16T17:26:23.500594Z",
          "iopub.status.idle": "2025-02-16T17:26:23.516632Z",
          "shell.execute_reply": "2025-02-16T17:26:23.515785Z",
          "shell.execute_reply.started": "2025-02-16T17:26:23.500780Z"
        },
        "id": "vj2oeNsYIJBy",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(model=lora_model,\n",
        "                  args = training_args,\n",
        "                  train_dataset=ds_split[\"train\"],\n",
        "                  eval_dataset=ds_split[\"test\"],\n",
        "                  compute_metrics = compute_metrics,\n",
        "                  data_collator = data_collator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T17:26:23.518042Z",
          "iopub.status.busy": "2025-02-16T17:26:23.517800Z",
          "iopub.status.idle": "2025-02-16T18:24:24.723321Z",
          "shell.execute_reply": "2025-02-16T18:24:24.722472Z",
          "shell.execute_reply.started": "2025-02-16T17:26:23.517990Z"
        },
        "id": "M9SnlRGHIJBy",
        "outputId": "6e41c37f-9628-4d08-d9a5-27f107a50000",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='232' max='232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [232/232 57:47, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.341000</td>\n",
              "      <td>0.695504</td>\n",
              "      <td>0.668110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.422700</td>\n",
              "      <td>0.309561</td>\n",
              "      <td>0.914005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.222700</td>\n",
              "      <td>0.340995</td>\n",
              "      <td>0.928440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.250800</td>\n",
              "      <td>0.296722</td>\n",
              "      <td>0.928557</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "results = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZTP8ZuHIJBz"
      },
      "source": [
        "# Let's Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "e629c602ba714698b1782f64d5c09bf2"
          ]
        },
        "execution": {
          "iopub.execute_input": "2025-02-16T18:24:24.724586Z",
          "iopub.status.busy": "2025-02-16T18:24:24.724253Z",
          "iopub.status.idle": "2025-02-16T18:24:24.988824Z",
          "shell.execute_reply": "2025-02-16T18:24:24.988185Z",
          "shell.execute_reply.started": "2025-02-16T18:24:24.724551Z"
        },
        "id": "QWkY1C5nIJBz",
        "outputId": "f37a0d39-85a1-4094-918d-02fc31236016",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e629c602ba714698b1782f64d5c09bf2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['ID', 'sentence', 'language'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_dataset = load_dataset(\"csv\", data_files=\"/kaggle/input/multi-lingual-sentiment-analysis/test.csv\")\n",
        "\n",
        "test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "1a941ebf22124ee4996e3421b0b1b393"
          ]
        },
        "execution": {
          "iopub.execute_input": "2025-02-16T18:24:24.989791Z",
          "iopub.status.busy": "2025-02-16T18:24:24.989553Z",
          "iopub.status.idle": "2025-02-16T18:24:25.102139Z",
          "shell.execute_reply": "2025-02-16T18:24:25.101505Z",
          "shell.execute_reply.started": "2025-02-16T18:24:24.989760Z"
        },
        "id": "TRGiZJZ5IJB0",
        "outputId": "2811b6a2-77f3-41d3-8b43-94e6ff211943",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a941ebf22124ee4996e3421b0b1b393",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'ID': 1, 'label': 'Positive'}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_sub = load_dataset(\"csv\", data_files=\"/kaggle/input/multi-lingual-sentiment-analysis/sample_submission.csv\")\n",
        "\n",
        "sample_sub['train'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZtiEMnCIJB1"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T18:24:25.103089Z",
          "iopub.status.busy": "2025-02-16T18:24:25.102870Z",
          "iopub.status.idle": "2025-02-16T18:24:25.108303Z",
          "shell.execute_reply": "2025-02-16T18:24:25.107382Z",
          "shell.execute_reply.started": "2025-02-16T18:24:25.103070Z"
        },
        "id": "IqS7vprGIJB1",
        "outputId": "b7d8ffae-e49c-45bf-c883-d7d87b4eceb2",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "from transformers import TextClassificationPipeline\n",
        "classifier = TextClassificationPipeline(model=model,\n",
        "                                       tokenizer=tokenizer,\n",
        "                                       framework='pt',\n",
        "                                       task=\"sentiment-analysis\",\n",
        "                                       #device = \"cuda\"\n",
        "                                       )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T18:24:25.109526Z",
          "iopub.status.busy": "2025-02-16T18:24:25.109210Z",
          "iopub.status.idle": "2025-02-16T18:24:25.126593Z",
          "shell.execute_reply": "2025-02-16T18:24:25.125732Z",
          "shell.execute_reply.started": "2025-02-16T18:24:25.109497Z"
        },
        "id": "-f8uJijOIJB1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model.config.id2label = {0:\"Negative\",1:\"Positive\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T18:24:25.127631Z",
          "iopub.status.busy": "2025-02-16T18:24:25.127405Z",
          "iopub.status.idle": "2025-02-16T18:24:25.914781Z",
          "shell.execute_reply": "2025-02-16T18:24:25.914101Z",
          "shell.execute_reply.started": "2025-02-16T18:24:25.127598Z"
        },
        "id": "VpMS9xZYIJB2",
        "outputId": "2fb04b63-4009-4038-be08-d384f794ef21",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample: 1120 mAh,   \n",
            "[{'label': 'Positive', 'score': 0.9206250905990601}]\n"
          ]
        }
      ],
      "source": [
        "sample = test_dataset['train'][0]['sentence']\n",
        "print(f\"Sample: {sample}\")\n",
        "prediction = classifier(sample)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T18:24:25.916148Z",
          "iopub.status.busy": "2025-02-16T18:24:25.915799Z",
          "iopub.status.idle": "2025-02-16T18:24:25.920502Z",
          "shell.execute_reply": "2025-02-16T18:24:25.919655Z",
          "shell.execute_reply.started": "2025-02-16T18:24:25.916117Z"
        },
        "id": "PD_YrQm_IJB2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Extract text data and ID from test_dataset (DatasetDict format)\n",
        "test_texts = test_dataset[\"train\"][\"sentence\"]  # Adjust key if needed\n",
        "test_ids = test_dataset[\"train\"][\"ID\"]  # Existing ID column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T18:24:25.921655Z",
          "iopub.status.busy": "2025-02-16T18:24:25.921405Z",
          "iopub.status.idle": "2025-02-16T18:27:59.585115Z",
          "shell.execute_reply": "2025-02-16T18:27:59.584089Z",
          "shell.execute_reply.started": "2025-02-16T18:24:25.921635Z"
        },
        "id": "eBKYi0bpIJB3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Run inference using the pipeline\n",
        "predictions = classifier(test_texts, batch_size=32)  # Batched for efficiency\n",
        "\n",
        "# Convert pipeline output to labels\n",
        "predicted_labels = [pred[\"label\"] for pred in predictions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T18:27:59.586341Z",
          "iopub.status.busy": "2025-02-16T18:27:59.586069Z",
          "iopub.status.idle": "2025-02-16T18:27:59.596362Z",
          "shell.execute_reply": "2025-02-16T18:27:59.595595Z",
          "shell.execute_reply.started": "2025-02-16T18:27:59.586309Z"
        },
        "id": "qUemticMIJB3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Save results to CSV\n",
        "output_df = pd.DataFrame({\"ID\": test_ids, \"label\": predicted_labels})\n",
        "output_df.to_csv(\"submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T18:27:59.597453Z",
          "iopub.status.busy": "2025-02-16T18:27:59.597212Z",
          "iopub.status.idle": "2025-02-16T18:27:59.614574Z",
          "shell.execute_reply": "2025-02-16T18:27:59.613783Z",
          "shell.execute_reply.started": "2025-02-16T18:27:59.597423Z"
        },
        "id": "FlxJdz_9IJCP",
        "outputId": "7858f0a8-f848-4be6-ae02-b5e9c64de5b1",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ID     label\n",
            "0   1  Positive\n",
            "1   2  Positive\n",
            "2   3  Positive\n",
            "3   4  Positive\n",
            "4   5  Negative\n",
            "5   6  Negative\n",
            "6   7  Positive\n",
            "7   8  Positive\n",
            "8   9  Negative\n",
            "9  10  Positive\n"
          ]
        }
      ],
      "source": [
        "print(output_df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T18:27:59.615645Z",
          "iopub.status.busy": "2025-02-16T18:27:59.615339Z",
          "iopub.status.idle": "2025-02-16T18:28:01.121801Z",
          "shell.execute_reply": "2025-02-16T18:28:01.121076Z",
          "shell.execute_reply.started": "2025-02-16T18:27:59.615617Z"
        },
        "id": "vtwG4ojdIJCQ",
        "outputId": "0400eb3c-fde9-438c-c023-0cf5b79e2ac7",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample:    ,    .      90% \n",
            "[{'label': 'Negative', 'score': 0.9348655939102173}]\n"
          ]
        }
      ],
      "source": [
        "sample = test_dataset['train'][11]['sentence']\n",
        "print(f\"Sample: {sample}\")\n",
        "prediction = classifier(sample)\n",
        "print(prediction)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 11098970,
          "sourceId": 93282,
          "sourceType": "competition"
        },
        {
          "isSourceIdPinned": true,
          "modelId": 91102,
          "modelInstanceId": 68809,
          "sourceId": 104449,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 30886,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
